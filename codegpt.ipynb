{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479d68da-061d-4368-8689-93f690be3d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from transformers import RobertaTokenizer, AutoModelForCausalLM,GPT2Tokenizer,GPT2LMHeadModel,GPT2Config\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0323605-1958-4f8f-8aa7-fb3fe57bf0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aa4095-ae35-42e7-a8ee-5614e894b884",
   "metadata": {},
   "source": [
    "## Set Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a7c597-7e9b-4d34-a042-0f3a4aa3a609",
   "metadata": {},
   "source": [
    "#### For Local Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bea3fb-1538-4f4d-8c41-a2fdc75d7cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Constants\n",
    "BATCH_SIZE = 8\n",
    "EPOCH_SIZE = 5\n",
    "LEARNING_RATE = .0001\n",
    "NL_SEQ_LEN = 20\n",
    "CODE_SEQ_LEN = 150\n",
    "\n",
    "RESUME_EPOCH = 0                            # Epoch to resume at (0 to start from the beginning)\n",
    "\n",
    "LOG_STEP = 1                                # Frequency of epoch's for logging\n",
    "PARAMS_FILE = './training_parameters.json'  # File where input parameters (from cmdline) are stored\n",
    "PL = 'python'                               # Programming language for fine-tuning the pretrained model\n",
    "DATA_SIZE = 2000                            # Size of the raw dataset that will be used (batch size * 4 is just for testing)\n",
    "MODEL_PATH = './checkpoints/codegpt_' + PL   # path to store the trained model\n",
    "MODEL_TYPE = 'codegpt'\n",
    "LOG_FILE = './logs/log_' + MODEL_TYPE + '_' + PL + '.txt'   # Base file path for storing model training \n",
    "MODE = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec935f28-b6fe-4d67-b004-b256277097fd",
   "metadata": {},
   "source": [
    "#### For rlogin training (COMMENT OUT WHEN RUNNING IPYNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90da7c99-799c-44a3-9272-96e0a4c185e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Enviornment Variables from extenal file \n",
    "if os.path.exists(PARAMS_FILE):\n",
    "    # params = pd.read_csv(PARAMS_FILE)\n",
    "    with open(PARAMS_FILE) as f:\n",
    "        params = json.load(f)\n",
    "    BATCH_SIZE = params['batch_size']\n",
    "    EPOCH_SIZE = params['epoch_size']\n",
    "    LEARNING_RATE = params['learning_rate']\n",
    "    NL_SEQ_LEN = params['nl_seq_len']\n",
    "    CODE_SEQ_LEN = params['code_seq_len']\n",
    "    RESUME_EPOCH = params['resume_epoch']\n",
    "    PL = params['pl_task']\n",
    "    DATA_SIZE = params['data_size']\n",
    "    MODEL_TYPE = params['pretrained']\n",
    "    LOG_STEP = params['log_step']\n",
    "    LOG_FILE = './logs/log_' + params['pretrained'] + '_' + params['pl_task'] + '.txt'\n",
    "    MODE = params['mode']\n",
    "    \n",
    "    # Check if files exist       \n",
    "    MODEL_PATH = './checkpoints/' + params['pretrained'] + '_' + params['pl_task']\n",
    "    if not os.path.isdir(MODEL_PATH):\n",
    "        os.mkdir(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb791b8-146e-49b6-a252-b79458f18b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RUNNING: {} with pl={}, mode={}, batch_size={}, epoch_size={}, learning_rate={}, nl_seq_len={}, code_seq_len={}, data_size={}, log_step={}, log_file={}, model_dir={} resume_epoch={}\".format(MODEL_TYPE, PL, MODE, BATCH_SIZE, EPOCH_SIZE, LEARNING_RATE, NL_SEQ_LEN, CODE_SEQ_LEN, DATA_SIZE, LOG_STEP, LOG_FILE, MODEL_PATH, RESUME_EPOCH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8fa17e-f10c-4fd0-b273-ecf77da37389",
   "metadata": {},
   "source": [
    "## Concode Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68fb99f-9c45-48e7-bb70-e61a61ce6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class concodeDataset(Dataset):\n",
    "    def __init__(self, tokenizer, data, block_size=150, mode='train'):\n",
    "\n",
    "            self.block_size = block_size\n",
    "            self.mode = mode\n",
    "            self.inputs = []\n",
    "            self.token_labels = []\n",
    "\n",
    "            datas = data\n",
    "\n",
    "            length = len(datas)\n",
    "\n",
    "            for idx in range(len(datas)):\n",
    "                x = datas.iloc[idx]\n",
    "                code = tokenizer.encode(x[\"Code\"])\n",
    "                nl = tokenizer.encode(x[\"NL\"])\n",
    "\n",
    "                input_ids, input_labels = self.pad_and_get_mask(code, nl, tokenizer)\n",
    "                self.inputs.append(input_ids)\n",
    "                self.token_labels.append(input_labels)\n",
    "\n",
    "\n",
    "    def pad_and_get_mask(self, code, nl, tokenizer):\n",
    "        if self.mode == 'test':\n",
    "            code = []\n",
    "        while (len(code) + len(nl) + 2 > self.block_size):\n",
    "            if (len(code) > len(nl)):\n",
    "                code = code[:-1]\n",
    "            else:\n",
    "                nl = nl[:-1]\n",
    "        if self.mode == 'train':\n",
    "            inputs = nl + [tokenizer.bos_token_id] + code + [tokenizer.eos_token_id]\n",
    "            labels = [1] * len(nl) + [2] * (len(code)+1) + [0]\n",
    "        else:\n",
    "            inputs = nl + [tokenizer.bos_token_id]\n",
    "            labels = [1] * len(nl) + [2]\n",
    "            return inputs, labels\n",
    "        assert len(inputs) <= self.block_size\n",
    "        pad_len = self.block_size - len(inputs)\n",
    "        inputs += [tokenizer.pad_token_id] * pad_len\n",
    "        labels += [0] * pad_len\n",
    "        assert len(inputs) == len(labels)\n",
    "        return inputs, labels\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return torch.tensor(self.inputs[item]), torch.tensor(self.token_labels[item])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b5857f-3182-4902-b3fd-c273a65c5df5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create or Load the PLBART Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b3ba84-d923-409d-a07c-cfbb409086c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Load trained and saved model if needed\n",
    "CodeGPT = GPT2LMHeadModel.from_pretrained(\"microsoft/CodeGPT-small-py-adaptedGPT2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb374800-284e-4895-af17-671cb505e749",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469b2031-c39f-4670-9878-4ce8b8e3808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"microsoft/CodeGPT-small-py-adaptedGPT2\",do_lower_case=True, bos_token='<s>', eos_token='</s>', pad_token='<pad>', unk_token='<|UNKNOWN|>', sep_token='concode_elem_sep')\n",
    "config = GPT2Config.from_pretrained(\"microsoft/CodeGPT-small-py-adaptedGPT2\")\n",
    "\n",
    "config.max_length = 150\n",
    "\n",
    "CodeGPT.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "CodeGPT.config.bos_token_id = tokenizer.bos_token_id\n",
    "CodeGPT.config.eos_token_id = tokenizer.eos_token_id\n",
    "CodeGPT.config.pad_token_id = tokenizer.pad_token_id\n",
    "CodeGPT = CodeGPT.to(device)\n",
    "\n",
    "if MODE == 'train':\n",
    "    data = pd.read_csv('./staqc_data/' + PL + '/train.csv')\n",
    "    val_data = pd.read_csv('./staqc_data/' + PL + '/val.csv')\n",
    "\n",
    "    dataset = concodeDataset(tokenizer, data, block_size=150)\n",
    "    val_dataset = concodeDataset(tokenizer, val_data,mode='train', block_size=150)\n",
    "\n",
    "    train_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, drop_last=True,shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, drop_last=True,shuffle=False)\n",
    "else:\n",
    "    test_data = pd.read_csv('./staqc_data/' + PL + '/test.csv')\n",
    "    test_dataset = concodeDataset(tokenizer, test_data, mode='test', block_size=20)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, drop_last=True,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04aaa81-188a-4187-a81d-27b446c521cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RESUME_EPOCH > 0:\n",
    "    saved_model_path = '{}/Epoch{}.pkl'.format(MODEL_PATH, str(RESUME_EPOCH))\n",
    "    if os.path.exists(saved_model_path):\n",
    "        CodeGPT.load_state_dict(torch.load(saved_model_path))\n",
    "    else:\n",
    "        print(\"WARNING: {} saved model does not exist! Training {} model from the epoch 0.\".format(saved_model_path, MODEL_TYPE))\n",
    "CodeGPT.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebea85f-b4be-42b2-acf2-8713b426603f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3e1f7a-d5aa-4c2f-9a96-5f0ac73ecbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "if MODE == 'train':\n",
    "    train_loss_graph = []\n",
    "    val_loss_graph = []\n",
    "    for i in range(EPOCH_SIZE):\n",
    "        tr_loss = 0.0\n",
    "        eval_loss = 0.0\n",
    "        for batch,token_labels in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            token_labels = token_labels.to(device)\n",
    "            attn_mask = torch.tensor(token_labels.clone().detach() != 0, dtype=torch.uint8)\n",
    "            loss_mask = torch.tensor(token_labels.clone().detach() == 2, dtype=torch.uint8)\n",
    "            attn_mask = attn_mask.to(device)\n",
    "            batch = batch.to(device)\n",
    "            CodeGPT.train()\n",
    "            out = CodeGPT(batch,attention_mask=attn_mask)\n",
    "            logits = out.logits\n",
    "            labels = batch\n",
    "            shift_logits = logits[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "            flatten_shift_loss_mask = loss_mask[..., :-1].contiguous().view(-1)\n",
    "            ids = torch.nonzero(flatten_shift_loss_mask).view(-1)\n",
    "            loss = criterion(shift_logits.view(-1, shift_logits.size(-1))[ids], shift_labels.view(-1)[ids])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tr_loss+= loss.item()\n",
    "\n",
    "        for batch,token_labels in val_dataloader:\n",
    "            CodeGPT.eval()\n",
    "            with torch.no_grad():\n",
    "                token_labels = token_labels.to(device)\n",
    "                attn_mask = torch.tensor(token_labels.clone().detach() != 0, dtype=torch.uint8)\n",
    "                loss_mask = torch.tensor(token_labels.clone().detach() == 2, dtype=torch.uint8)\n",
    "                attn_mask = attn_mask.to(device)\n",
    "                batch = batch.to(device)\n",
    "                out = CodeGPT(batch,attention_mask=attn_mask)\n",
    "                logits = out.logits\n",
    "                labels = batch\n",
    "                shift_logits = logits[..., :-1, :].contiguous()\n",
    "                shift_labels = labels[..., 1:].contiguous()\n",
    "                flatten_shift_loss_mask = loss_mask[..., :-1].contiguous().view(-1)\n",
    "                ids = torch.nonzero(flatten_shift_loss_mask).view(-1)\n",
    "                loss = criterion(shift_logits.view(-1, shift_logits.size(-1))[ids], shift_labels.view(-1)[ids])\n",
    "                eval_loss += loss.item()\n",
    "                #print(eval_loss)\n",
    "\n",
    "\n",
    "        tr_loss = tr_loss/len(train_dataloader)\n",
    "        eval_loss = eval_loss/len(val_dataloader)\n",
    "        train_loss_graph.append(tr_loss)\n",
    "        val_loss_graph.append(eval_loss)\n",
    "        print(\"Epoch: {} Train Loss: {} Val Loss: {}\".format(i+1,tr_loss,eval_loss))\n",
    "        # Save checkpoint\n",
    "        torch.save(model.state_dict(), '{}/Epoch{}.pkl'.format(MODEL_PATH, str(i+1))) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb27084-f71d-4494-8eaa-9c73d6c8509e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Graph Training vs Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7c6857-764b-4d9c-bc75-3e09bfaf3ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == 'train':\n",
    "    plt.plot(train_loss_graph,'k')\n",
    "    plt.plot(val_loss_graph,'y')\n",
    "    plt.legend([\"Training Loss\",\"Validation Loss\"])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss vs Epoch\")\n",
    "    plt.savefig(MODEL_TYPE.upper() + '_' + PL.upper() + '_Training_Validation_Loss.png')\n",
    "\n",
    "    losses = pd.DataFrame({'Tr_Loss': train_loss_graph, 'Val_Loss': val_loss_graph})\n",
    "\n",
    "    losses.to_csv('Training_loss_py_GPT.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7f76c4-cdb4-4555-b9d8-713d7e6b7833",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989df4c7-c65e-4651-80e9-3188037c9cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == 'test':\n",
    "\n",
    "    print(\"Testing.....\")\n",
    "    batch_num = 0\n",
    "    inputs, hypothesis, reference = [], [], []\n",
    "    CodeGPT.eval()\n",
    "    for batch, token_labels in test_loader:\n",
    "        step+=1\n",
    "        if step >= 2000:\n",
    "            step=0\n",
    "            break\n",
    "        inputs = batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = CodeGPT.generate(inputs, max_length=150, num_beams=10, temperature=0.7, early_stopping=False, top_k=70, \\\n",
    "                                   bos_token_id=tokenizer.bos_token_id, eos_token_id=tokenizer.eos_token_id, pad_token_id=tokenizer.pad_token_id)\n",
    "            generation = tokenizer.decode(outputs[0])[len(tokenizer.decode(inputs[0])):]\n",
    "            preds.append(generation.rstrip(\"<pad>\"))\n",
    "\n",
    "    d = pd.DataFrame({'predicted_codes':preds})\n",
    "    d.to_csv(\"SQL_predictions_CodeGPT.csv\")\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
